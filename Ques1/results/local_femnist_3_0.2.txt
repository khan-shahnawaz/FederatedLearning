Arguments:
	              alpha : 0.0
	         batch_size : 32
	           boosting : 1
	  clients_per_round : 10
	          comm_freq : 0.1
	data_partition_seed : 0
	            dataset : femnist
	       decay_factor : 1.0
	        dynamic_lam : 0
	         eval_every : 10
	            fedmgda : 0
	        fedmgda_eps : 0.0
	     finetune_iters : 40
	         global_reg : -1.0
	  gradient_clipping : 0
	             k_loss : 0
	             k_norm : 0
	               krum : 0
	                lam : 0.0
	       lambda_l2sgd : 0
	      learning_rate : 0.1
	        local_iters : 2
	             median : 0
	              mkrum : 0
	              model : cnn
	       model_params : (62,)
	      num_corrupted : 41
	         num_epochs : 1
	         num_rounds : 1000
	          optimizer : ditto
	                  q : 0.0
	     random_updates : 0
	           sampling : 2
	               seed : 0
Using global-regularized multi-task learning to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/443.70k flops)
  dense/kernel/Initializer/random_uniform (200.70k/401.41k flops)
    dense/kernel/Initializer/random_uniform/mul (200.70k/200.70k flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  conv2d_1/kernel/Initializer/random_uniform (12.80k/25.60k flops)
    conv2d_1/kernel/Initializer/random_uniform/mul (12.80k/12.80k flops)
    conv2d_1/kernel/Initializer/random_uniform/sub (1/1 flops)
  dense_1/kernel/Initializer/random_uniform (7.94k/15.87k flops)
    dense_1/kernel/Initializer/random_uniform/mul (7.94k/7.94k flops)
    dense_1/kernel/Initializer/random_uniform/sub (1/1 flops)
  conv2d/kernel/Initializer/random_uniform (400/801 flops)
    conv2d/kernel/Initializer/random_uniform/mul (400/400 flops)
    conv2d/kernel/Initializer/random_uniform/sub (1/1 flops)
  gradients_1/Sum_grad/Maximum (2/2 flops)
  gradients_1/Sum_1_grad/Maximum (2/2 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)
  sparse_softmax_cross_entropy_loss/div (1/1 flops)
  sparse_softmax_cross_entropy_loss/Greater (1/1 flops)
  sparse_softmax_cross_entropy_loss/Equal (1/1 flops)
  gradients_1/Sum_grad/add (1/1 flops)
  gradients_1/Sum_1_grad/add (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/div_grad/mul (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/div_grad/RealDiv_2 (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/div_grad/RealDiv_1 (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/div_grad/RealDiv (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/div_grad/Neg (1/1 flops)
  dropout_1/random_uniform/sub (1/1 flops)
  dropout/random_uniform/sub (1/1 flops)

======================End of Report==========================
206 Clients in Total
---10 workers per communication round---
[  8 190  83 201 173  34  67  54  13  28 181 164 145  15 174 134 139  91
 167  92   9  44  77  48  55  49 129 136  64  43 204  98  41  10  20 196
  17 102  63 162 186]
At round 10 training accu: 0.023107959408240616, loss: 4.145679002520012
At round 10 test accu: 0.022607022607022607
At round 10 malicious test accu: 0.013665594855305467
At round 10 benign test accu: 0.024834768676146604
variance of the performance:  0.001021984545694165
At round 20 training accu: 0.03325589925418755, loss: 4.110778784583793
At round 20 test accu: 0.02629469296135963
At round 20 malicious test accu: 0.016881028938906754
At round 20 benign test accu: 0.028640096134588424
variance of the performance:  0.0010290484696786721
At round 30 training accu: 0.03904307780087215, loss: 4.080016570836129
At round 30 test accu: 0.030784030784030785
At round 30 malicious test accu: 0.017684887459807074
At round 30 benign test accu: 0.034047666733426796
variance of the performance:  0.0014268087968742692
At round 40 training accu: 0.04690875005094347, loss: 4.053561716357221
At round 40 test accu: 0.030784030784030785
At round 40 malicious test accu: 0.008038585209003215
At round 40 benign test accu: 0.03645103144402163
variance of the performance:  0.0012970183814928484
At round 50 training accu: 0.04972082976729021, loss: 4.024290065735842
At round 50 test accu: 0.03527336860670194
At round 50 malicious test accu: 0.00964630225080386
At round 50 benign test accu: 0.041658321650310436
variance of the performance:  0.0013197708091965258
At round 60 training accu: 0.05351102416758365, loss: 4.000569437352448
At round 60 test accu: 0.03767837101170435
At round 60 malicious test accu: 0.011254019292604502
At round 60 benign test accu: 0.04426196675345484
variance of the performance:  0.0014383722594477695
At round 70 training accu: 0.054855931858010354, loss: 3.9800653558695243
At round 70 test accu: 0.04008337341670675
At round 70 malicious test accu: 0.01607717041800643
At round 70 benign test accu: 0.04606449028640096
variance of the performance:  0.001924780205128314
At round 80 training accu: 0.056445368219423725, loss: 3.9555357580114587
At round 80 test accu: 0.04457271123937791
At round 80 malicious test accu: 0.01929260450160772
At round 80 benign test accu: 0.05087121970759063
variance of the performance:  0.0019018420433205723
At round 90 training accu: 0.05889065492929046, loss: 3.9404630157588705
At round 90 test accu: 0.04312970979637646
At round 90 malicious test accu: 0.008842443729903537
At round 90 benign test accu: 0.05167234127778891
variance of the performance:  0.0017666047009747671
At round 100 training accu: 0.06418877613400172, loss: 3.9340891385664345
At round 100 test accu: 0.0456950456950457
At round 100 malicious test accu: 0.008038585209003215
At round 100 benign test accu: 0.05507710795113158
variance of the performance:  0.001892253463884537
At round 110 training accu: 0.06349594489953947, loss: 3.926492135730841
At round 110 test accu: 0.046176046176046176
At round 110 malicious test accu: 0.012057877813504822
At round 110 benign test accu: 0.054676547166032444
variance of the performance:  0.0018197133276505392
At round 120 training accu: 0.06427028569099727, loss: 3.906949152081492
At round 120 test accu: 0.04152637485970819
At round 120 malicious test accu: 0.008038585209003215
At round 120 benign test accu: 0.04986981774484278
variance of the performance:  0.0019035128177498108
At round 130 training accu: 0.06361820923503281, loss: 3.9017400743228987
At round 130 test accu: 0.042328042328042326
At round 130 malicious test accu: 0.01045016077170418
At round 130 benign test accu: 0.05027037852994192
variance of the performance:  0.0017043973817162548
At round 140 training accu: 0.06594123160940621, loss: 3.9006195078367574
At round 140 test accu: 0.04826038159371493
At round 140 malicious test accu: 0.012057877813504822
At round 140 benign test accu: 0.05728019226917685
variance of the performance:  0.0019024589780700706
At round 150 training accu: 0.06801972531279292, loss: 3.888021606345114
At round 150 test accu: 0.044733044733044736
At round 150 malicious test accu: 0.014469453376205787
At round 150 benign test accu: 0.05227318245543761
variance of the performance:  0.0019159166808889502
At round 160 training accu: 0.06532990993193952, loss: 3.8851666424362574
At round 160 test accu: 0.0439313772647106
At round 160 malicious test accu: 0.008842443729903537
At round 160 benign test accu: 0.05267374324053675
variance of the performance:  0.0021214977959206145
At round 170 training accu: 0.06716387496433956, loss: 3.8658107702163758
At round 170 test accu: 0.05114638447971781
At round 170 malicious test accu: 0.00964630225080386
At round 170 benign test accu: 0.061486080512717804
variance of the performance:  0.002086986923351964
At round 180 training accu: 0.07066878591514855, loss: 3.854078582530549
At round 180 test accu: 0.050024050024050026
At round 180 malicious test accu: 0.02009646302250804
At round 180 benign test accu: 0.057480472661726414
variance of the performance:  0.001820298113498841
At round 190 training accu: 0.0690385947752374, loss: 3.854000061469842
At round 190 test accu: 0.04922238255571589
At round 190 malicious test accu: 0.011254019292604502
At round 190 benign test accu: 0.05868215501702383
variance of the performance:  0.001624366187806229
At round 200 training accu: 0.06940538778171741, loss: 3.8399614727516047
At round 200 test accu: 0.042488375821709154
At round 200 malicious test accu: 0.013665594855305467
At round 200 benign test accu: 0.04966953735229321
variance of the performance:  0.001670671277390771
At round 210 training accu: 0.0707502954721441, loss: 3.8280879550756137
At round 210 test accu: 0.04553471220137887
At round 210 malicious test accu: 0.008842443729903537
At round 210 benign test accu: 0.054676547166032444
variance of the performance:  0.0019141051272246166
At round 220 training accu: 0.06887557566124627, loss: 3.8280505110087737
At round 220 test accu: 0.042167708834375504
At round 220 malicious test accu: 0.012861736334405145
At round 220 benign test accu: 0.04946925695974364
variance of the performance:  0.0015312409618362104
At round 230 training accu: 0.06936463300321963, loss: 3.814569653618203
At round 230 test accu: 0.05130671797338464
At round 230 malicious test accu: 0.01607717041800643
At round 230 benign test accu: 0.06008411776487082
variance of the performance:  0.0025242537570794423
At round 240 training accu: 0.07193218404857969, loss: 3.8087540284128933
At round 240 test accu: 0.049062049062049064
At round 240 malicious test accu: 0.013665594855305467
At round 240 benign test accu: 0.057881033446825554
variance of the performance:  0.0021175851000902143
At round 250 training accu: 0.07217671271956637, loss: 3.7850783528386516
At round 250 test accu: 0.051627384960718295
At round 250 malicious test accu: 0.017684887459807074
At round 250 benign test accu: 0.06008411776487082
variance of the performance:  0.002260975621481486
At round 260 training accu: 0.07062803113665077, loss: 3.766243244279503
At round 260 test accu: 0.047779381112714445
At round 260 malicious test accu: 0.013665594855305467
At round 260 benign test accu: 0.056278790306429
variance of the performance:  0.002233061393609164
At round 270 training accu: 0.07180991971308635, loss: 3.7623571107754543
At round 270 test accu: 0.04793971460638127
At round 270 malicious test accu: 0.013665594855305467
At round 270 benign test accu: 0.05647907069897857
variance of the performance:  0.001897136856465124
At round 280 training accu: 0.07091331458613523, loss: 3.7547727006423366
At round 280 test accu: 0.05114638447971781
At round 280 malicious test accu: 0.017684887459807074
At round 280 benign test accu: 0.05948327658722211
variance of the performance:  0.002187220829745698
At round 290 training accu: 0.07193218404857969, loss: 3.7487082857226093
At round 290 test accu: 0.05242905242905243
At round 290 malicious test accu: 0.01527331189710611
At round 290 benign test accu: 0.06168636090526738
variance of the performance:  0.0021468795460017932
At round 300 training accu: 0.0740514325304642, loss: 3.7373657704526795
At round 300 test accu: 0.04970338303671637
At round 300 malicious test accu: 0.01527331189710611
At round 300 benign test accu: 0.058281594231924694
variance of the performance:  0.0016982855484373367
At round 310 training accu: 0.07132086237111301, loss: 3.7327332452820765
At round 310 test accu: 0.050024050024050026
At round 310 malicious test accu: 0.016881028938906754
At round 310 benign test accu: 0.058281594231924694
variance of the performance:  0.0020628362154364627
At round 320 training accu: 0.07401067775196642, loss: 3.729269080384172
At round 320 test accu: 0.043610710277376945
At round 320 malicious test accu: 0.013665594855305467
At round 320 benign test accu: 0.051071500100140194
variance of the performance:  0.002033862924115989
At round 330 training accu: 0.07062803113665077, loss: 3.723682534934188
At round 330 test accu: 0.052749719416386086
At round 330 malicious test accu: 0.01607717041800643
At round 330 benign test accu: 0.061886641297816944
variance of the performance:  0.001939974519085309
At round 340 training accu: 0.07164690059909525, loss: 3.718136183638471
At round 340 test accu: 0.04489337822671156
At round 340 malicious test accu: 0.014469453376205787
At round 340 benign test accu: 0.05247346284798718
variance of the performance:  0.0018520952002165825
At round 350 training accu: 0.07466275420793088, loss: 3.702910554891461
At round 350 test accu: 0.05114638447971781
At round 350 malicious test accu: 0.02009646302250804
At round 350 benign test accu: 0.0588824354095734
variance of the performance:  0.0022300649774204388
At round 360 training accu: 0.07193218404857969, loss: 3.688293325272847
At round 360 test accu: 0.0522687189353856
At round 360 malicious test accu: 0.012057877813504822
At round 360 benign test accu: 0.062287202082916084
variance of the performance:  0.001845274496789785
At round 370 training accu: 0.07331784651750417, loss: 3.6753129587539974
At round 370 test accu: 0.050344717011383676
At round 370 malicious test accu: 0.016881028938906754
At round 370 benign test accu: 0.05868215501702383
variance of the performance:  0.0022137104074216553
At round 380 training accu: 0.07087255980763744, loss: 3.678528594587865
At round 380 test accu: 0.049062049062049064
At round 380 malicious test accu: 0.014469453376205787
At round 380 benign test accu: 0.05768075305427599
variance of the performance:  0.0018324526016302361
